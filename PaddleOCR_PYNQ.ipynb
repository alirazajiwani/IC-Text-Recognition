{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9b4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import socket\n",
    "import pickle\n",
    "import struct\n",
    "import time\n",
    "import io\n",
    "import PIL.Image\n",
    "import IPython.display\n",
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib import Button\n",
    "\n",
    "\n",
    "try:\n",
    "    base = BaseOverlay(\"base.bit\")\n",
    "    # Isolate BTN0 for capturing images\n",
    "    btn0 = base.buttons[0]\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing PYNQ overlay or buttons: {e}\")\n",
    "    print(\"Please ensure the bitstream is correct and you are running this on a PYNQ board.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "\n",
    "# --- Preprocessing Function ---\n",
    "\n",
    "def preprocess_for_ocr(image, blur_t=200, contrast_t=255,\n",
    "                       std_t=40, edge_t=50):\n",
    "    \"\"\"\n",
    "    Applies a series of preprocessing steps to an image to prepare it for OCR.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Blurriness check\n",
    "    lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    if lap_var < blur_t:\n",
    "        processed = cv2.bilateralFilter(gray, 9, 15, 15)\n",
    "    else:\n",
    "        processed = gray\n",
    "\n",
    "    # Resize\n",
    "    h, w = int(processed.shape[0]*3), int(processed.shape[1]*3)\n",
    "    if h < 3000 and w < 6000:\n",
    "        processed = cv2.resize(processed, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)\n",
    "    else:\n",
    "        scale_factor = min(6000 / processed.shape[0], 3000 / processed.shape[1], 3.0)\n",
    "        new_h, new_w = int(processed.shape[0] * scale_factor), int(processed.shape[1] * scale_factor)\n",
    "        processed = cv2.resize(processed, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Contrast enhancement\n",
    "    contrast = np.max(processed) - np.min(processed)\n",
    "    if contrast < contrast_t:\n",
    "        clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(18, 18))\n",
    "        processed = clahe.apply(processed)\n",
    "\n",
    "    # Thresholding\n",
    "    std_intensity = np.std(processed)\n",
    "    if std_intensity < std_t:\n",
    "        block_size = max(3, (min(processed.shape) // 10) | 1)\n",
    "        processed = cv2.adaptiveThreshold(processed, 255,\n",
    "                                          cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                          cv2.THRESH_BINARY,\n",
    "                                          block_size, 2)\n",
    "\n",
    "    # Sharpening\n",
    "    edge_strength = cv2.Canny(processed, 100, 200).sum() / 1000\n",
    "    if edge_strength < edge_t:\n",
    "        sharpen_kernel = np.array([[-1, -1, -1],\n",
    "                                   [-1,  9, -1],\n",
    "                                   [-1, -1, -1]])\n",
    "        processed = cv2.filter2D(processed, -1, sharpen_kernel)\n",
    "\n",
    "    return processed\n",
    "\n",
    "\n",
    "# --- Helper Function for Smoother Jupyter Video Display ---\n",
    "def array_to_image_widget(frame, quality=75):\n",
    "    \"\"\"\n",
    "    Converts a NumPy array (frame) to a compressed JPEG IPython Image widget.\n",
    "    Using JPEG with a quality setting improves display speed over PNG.\n",
    "    \"\"\"\n",
    "    # Convert color space from BGR (OpenCV standard) to RGB for display\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create an in-memory binary stream\n",
    "    f = io.BytesIO()\n",
    "    \n",
    "    # Save the frame to the stream in JPEG format for faster processing\n",
    "    pil_img = PIL.Image.fromarray(rgb_frame)\n",
    "    pil_img.save(f, 'jpeg', quality=quality)\n",
    "    \n",
    "    # Create an IPython Image object from the binary data\n",
    "    return IPython.display.Image(data=f.getvalue(), format='jpeg')\n",
    "\n",
    "\n",
    "# --- Main Application Logic ---\n",
    "\n",
    "# --- Socket Setup ---\n",
    "HOST = '192.168.137.1'  # IMPORTANT: Replace with your PC's IP address\n",
    "PORT = 5002\n",
    "\n",
    "sock = None\n",
    "try:\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    print(f\"Attempting to connect to Host PC at {HOST}:{PORT}...\")\n",
    "    sock.connect((HOST, PORT))\n",
    "    print(\"‚úÖ Connection Successful!\")\n",
    "except socket.error as e:\n",
    "    print(f\"‚ùå Socket Connection Error: {e}\")\n",
    "    print(\"Please ensure the PC-side script is running and the IP address is correct.\")\n",
    "    exit()\n",
    "\n",
    "# --- Camera Setup ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Error: Could not access the camera.\")\n",
    "    if sock:\n",
    "        sock.close()\n",
    "    exit()\n",
    "\n",
    "# --- User Instructions ---\n",
    "frame_id = 0\n",
    "print(\"\\nüì∑ Real-time video is active.\")\n",
    "print(\"Press BTN0 on the PYNQ board to capture and send a snapshot for OCR.\")\n",
    "print(\"To stop, interrupt the kernel in Jupyter (Menu > Kernel > Interrupt).\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# This object will hold the display area in Jupyter, allowing for smooth updates\n",
    "display_handle = None\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # --- Capture and Display Real-time Video ---\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"‚ö†Ô∏è Failed to grab a frame from the camera. Retrying...\")\n",
    "            time.sleep(0.5)\n",
    "            continue\n",
    "\n",
    "        # Convert frame to an image widget for display\n",
    "        img_widget = array_to_image_widget(frame, quality=75)\n",
    "        \n",
    "        # This logic updates the image in place, preventing flickering\n",
    "        if display_handle is None:\n",
    "            display_handle = IPython.display.display(img_widget, display_id=True)\n",
    "        else:\n",
    "            display_handle.update(img_widget)\n",
    "        \n",
    "        # --- Check for BTN0 Press ---\n",
    "        if btn0.read() == 1:\n",
    "            print(f\"\\nBTN0 pressed! Capturing and processing snapshot...\")\n",
    "            \n",
    "            # Use the latest frame captured from the camera\n",
    "            frame_id += 1\n",
    "            processed_image = preprocess_for_ocr(frame)\n",
    "            filename = f\"frame_{frame_id}_btn0.png\"\n",
    "\n",
    "            # Give visual feedback by showing the processed image\n",
    "            processed_widget = array_to_image_widget(cv2.cvtColor(processed_image, cv2.COLOR_GRAY2BGR))\n",
    "            display_handle.update(processed_widget)\n",
    "            \n",
    "            # Serialize and send the processed image and filename to the PC\n",
    "            payload = (filename, processed_image)\n",
    "            data = pickle.dumps(payload)\n",
    "            size = struct.pack(\"Q\", len(data))\n",
    "            sock.sendall(size + data)\n",
    "            \n",
    "            print(f\"‚úÖ Successfully sent: {filename}\")\n",
    "            \n",
    "            # Wait for the button to be released to avoid multiple captures\n",
    "            print(\"Waiting for button to be released...\")\n",
    "            while btn0.read() == 1:\n",
    "                time.sleep(0.1)\n",
    "            print(\"Button released. Resuming live view.\")\n",
    "\n",
    "        # A short pause to prevent the loop from overwhelming the CPU\n",
    "        time.sleep(0.03)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nüõë Stream stopped by user (Kernel Interrupt).\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "finally:\n",
    "    # --- Cleanup ---\n",
    "    cap.release()\n",
    "    if sock:\n",
    "        print(\"Sending termination signal to host...\")\n",
    "        try:\n",
    "            # Send a packet of size 0 to signal the end of the stream\n",
    "            sock.sendall(struct.pack(\"Q\", 0))\n",
    "            sock.close()\n",
    "            print(\"‚úÖ Connection closed and resources released.\")\n",
    "        except socket.error as e:\n",
    "            print(f\"‚ö†Ô∏è Could not send termination signal cleanly: {e}\")\n",
    "    # Clear the final image from the Jupyter output\n",
    "    IPython.display.clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Socket Setup ---\n",
    "HOST = '192.168.137.1'  # Replace with your PC's IP\n",
    "PORT = 5002\n",
    "\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "sock.connect((HOST, PORT))\n",
    "\n",
    "# Open USB camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Error: Could not access the camera.\")\n",
    "    sock.close()\n",
    "    exit()\n",
    "\n",
    "frame_id = 0\n",
    "print(\"üì∑ Streaming from camera... Interrupt kernal to stop.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"‚ö†Ô∏è Failed to grab frame\")\n",
    "            continue\n",
    "\n",
    "        frame_id += 1\n",
    "        processed = preprocess_for_ocr(frame)\n",
    "        filename = f\"frame_{frame_id}.png\"\n",
    "\n",
    "        # --- Display processed frame inline ---\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.imshow(processed, cmap='gray')\n",
    "        plt.title(f\"Processed Frame {frame_id}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        # --- Serialize and send ---\n",
    "        payload = (filename, processed)\n",
    "        data = pickle.dumps(payload)\n",
    "        size = struct.pack(\"Q\", len(data))\n",
    "        sock.sendall(size + data)\n",
    "\n",
    "        print(f\"‚úÖ Sent frame {frame_id}\")\n",
    "\n",
    "        # Wait before next capture\n",
    "        time.sleep(10)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"üõë Stream stopped by user.\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    sock.sendall(struct.pack(\"Q\", 0))  # Termination signal\n",
    "    sock.close()\n",
    "    print(\"‚úÖ Connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9d43a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
